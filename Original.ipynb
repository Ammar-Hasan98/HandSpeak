{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5770f70-c8ac-467a-8eeb-1c673b734abe",
   "metadata": {},
   "source": [
    "## Installing necessary libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1b0c2a-3008-4564-b31f-59330c58c8bb",
   "metadata": {},
   "source": [
    "## Importing essential libraries for data processing, model building, and visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e0c3d6f-7ed0-4c80-bc55-f80c9caf92a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp    # For MediaPipe's hand and pose tracking utilities (Real-time)\n",
    "import tensorflow as tf   # Core machine learning library for building models\n",
    "import keras              # High-level neural networks API, runs on TensorFlow\n",
    "import numpy as np        # Numerical operations and array handling\n",
    "import pandas as pd       # Data manipulation and analysis\n",
    "import os                 # Interacting with the operating system\n",
    "import shutil             # High-level file operations (e.g., copy, delete)\n",
    "import datetime as dt     \n",
    "import matplotlib.pyplot as plt # Plotting graphs and visualizations\n",
    "import seaborn as sns        # Data visualization library\n",
    "from tqdm import tqdm        # Progress bar for loops\n",
    "import glob                  # File pattern matching (for file paths)\n",
    "import cv2                   # OpenCV for image processing\n",
    "from keras.utils import to_categorical  # Converts labels to categorical format\n",
    "from keras.models import Sequential     # For building sequential neural network models\n",
    "from keras.layers import Bidirectional, LSTM, Dense  # Layers for RNN (Recurrent Neural Network) models\n",
    "from keras.callbacks import EarlyStopping  #Stops training early if performance plateaus\n",
    "from sklearn.metrics import multilabel_confusion_matrix, accuracy_score # Metrics for model evaluation\n",
    "from sklearn.model_selection import train_test_split     \n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f7db34-853c-4b23-a1ad-c0cb1975598b",
   "metadata": {},
   "source": [
    "## Initialize MediaPipe Holistic Model and Drawing Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7cd18873-105f-448f-a07b-3d9267452ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Holistic object to detect keypoints (landmarks) such as: pose, face, and hands keypoints\n",
    "mp_holistic = mp.solutions.holistic #Creating Object\n",
    "\n",
    "# Drawing utilities for detected landmarks on images or video frames.\n",
    "mp_drawing = mp.solutions.drawing_utils "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b19ac2-24d2-43cc-87ec-31263340fbcb",
   "metadata": {},
   "source": [
    "## Function to Detect Keypoints Using MediaPipe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824890f0-0292-4282-ae72-9d2c318e1e9f",
   "metadata": {},
   "source": [
    "This function takes an input image and a MediaPipe model (like mp_holistic) to perform **landmark detection**. It prepares the image by converting color formats (as OpenCV uses BGR, while MediaPipe uses RGB).\n",
    "- the output of model.process(image): An Object contains attributes/(collection of landmark points) like pose_landmarks(x,y,z), left_hand_landmarks(x,y,z), right_hand_landmarks(x,y,z)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3f969bb-d00d-4546-8d49-1a07a9ff9ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mediapipe_detection(image, model):\n",
    "    \"\"\"\n",
    "    Perform landmark detection on an image using a specified MediaPipe model.\n",
    "    \"\"\"\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # COLOR CONVERSION BGR 2 RGB\n",
    "    image.flags.writeable = False                  # Image is no longer writeable ; to improve performance during processing\n",
    "    results = model.process(image)                 # Make prediction / Run the holistic model to detect and process keypoints\n",
    "    image.flags.writeable = True                   # Image is now writeable for further processing\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR) # COLOR CONVERSION RGB 2 BGR\n",
    "    return image, results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd50153-1726-48f2-86cb-5044e1fdd91c",
   "metadata": {},
   "source": [
    "## Function to Draw Styled Landmarks on an Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17cffd8b-8988-4462-b6b7-f39f976a49e0",
   "metadata": {},
   "source": [
    "- This function takes an image and a results object containing detected keypoints.\n",
    "- For each type of keypoint (pose, left hand, right hand), it uses mp_drawing.draw_landmarks to draw connections and landmarks with specified styles (color, thickness, and circle radius) for easier visualization.\n",
    "- DrawingSpec allows customizing how the landmarks and connections appear on the image, which helps distinguish between different parts visually."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bcf5b5f-b055-4e15-8646-fe82862a3183",
   "metadata": {},
   "source": [
    "-- `right_hand_landmarks` is the actual data (coordinates of hand points)\n",
    "-- `mp_holistic.HAND_CONNECTIONS` Specifies how to connect these keypoints to form a visual hand skeleton.\n",
    "-- `draw_landmarks` : Uses the HAND_CONNECTIONS list to connect these detected points visually on image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40694711-be9d-4b6c-8b6b-604339009964",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_styled_landmarks(image, results):\n",
    "\n",
    "    \"\"\"\n",
    "    Draw styled landmarks on the image for detected pose, left hand, and right hand keypoints.\n",
    "    \"\"\"\n",
    "    # Draw pose connections\n",
    "    mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS, #pose_landmark == collection of landmark points POSE_CONNECTIONS == connect pairs \n",
    "                             mp_drawing.DrawingSpec(color=(80,22,10), thickness=2, circle_radius=4),# Color/style for landmarks \n",
    "                             mp_drawing.DrawingSpec(color=(80,44,121), thickness=2, circle_radius=2) # Color/style for connections\n",
    "                             ) \n",
    "    # Draw left hand connections\n",
    "    mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                             mp_drawing.DrawingSpec(color=(121,22,76), thickness=2, circle_radius=4), \n",
    "                             mp_drawing.DrawingSpec(color=(121,44,250), thickness=2, circle_radius=2)\n",
    "                             ) \n",
    "    # Draw right hand connections  \n",
    "    mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                             mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4), \n",
    "                             mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n",
    "                             )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4aac09-493d-43d0-a764-269d89a73b50",
   "metadata": {},
   "source": [
    "## Function to Adjust Landmarks Based on a Center Point"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eab2656-950c-49e4-b283-b728855e98ca",
   "metadata": {},
   "source": [
    "**Function Purpose:**\n",
    "This function takes an array of landmark coordinates and centers them around a specified point. This can help normalize positions, such as making all hand landmarks relative to the wrist or a central point, which is useful for consistency in gesture recognition.\n",
    "\n",
    "**Centering landmarks is often done to standardize gesture positions, so the same gesture looks similar regardless of where the hand is in the frame.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fad410f6-918d-444b-b06f-1765a9c122c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_landmarks(arr,center):\n",
    "\n",
    "    \"\"\"\n",
    "    Adjusts the coordinates of landmarks by centering them around a given point.\n",
    "    \"\"\"\n",
    "    # Reshape the array to have shape (n, 3)\n",
    "    # Convert the flattened array of landmarks into (n, 3) shape, where n is the number of landmarks and 3 represents x, y, z coordinates\n",
    "    \n",
    "    arr_reshaped = arr.reshape(-1, 3)  \n",
    "\n",
    "    \n",
    "    # Repeat the center array to have shape (n, 3)\n",
    "    # Repeat the center coordinates n times to match the shape of the landmark array for element-wise subtraction\n",
    "    \n",
    "    center_repeated = np.tile(center, (len(arr_reshaped), 1)) \n",
    "\n",
    "    \n",
    "    # Subtract the center array from the arr array\n",
    "    # Effectively centering all landmarks around this point\n",
    "    \n",
    "    arr_adjusted = arr_reshaped - center_repeated\n",
    "\n",
    "    \n",
    "    # Reshape arr_adjusted back to shape (n*3,)\n",
    "    # Flatten the adjusted array back to its original (n*3,) shape\n",
    "    #Using -1 lets you reshape an array without having to manually calculate the size for that dimension, as NumPy will infer it based on the total element count.\n",
    "    \n",
    "    arr_adjusted = arr_adjusted.reshape(-1) \n",
    "\n",
    "    \n",
    "    return(arr_adjusted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5116a4ab-9aab-47a2-b5be-126e40df640c",
   "metadata": {},
   "source": [
    "## Function to Extract and Adjust Keypoints from Detected Landmarks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92745ad0-6e85-46bf-878d-e0076940a359",
   "metadata": {},
   "source": [
    "This function extracts keypoints for the body’s pose, left hand, and right hand from the **results** object produced by MediaPipe. It then adjusts these keypoints to be centered around specific reference points (like the nose or wrists), making gesture recognition more consistent.\n",
    "\n",
    "\n",
    "`.flatten()`: Flattens the array into a one-dimensional (1D) array.\n",
    "\n",
    "`[[res.x, res.y, res.z] for res in results.pose_landmarks.landmark]` : \n",
    "- This is a list comprehension, a concise way to create lists in Python.\n",
    "- It iterates over each landmark in results.pose_landmarks.landmark.\n",
    "- For each landmark, it extracts the x, y, and z coordinates: [res.x, res.y, res.z]\n",
    "\n",
    "`np.zeros(33*3)` : matching the shape of the array created when landmarks are detected. This is useful to maintain consistency in data shape.\n",
    "\n",
    "Purpose of Selecting the Nose Landmark:\n",
    "Using the nose coordinates as a reference (or \"center\") point allows us to normalize the position of other landmarks relative to the nose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "727f749b-733c-4e42-867c-e7f00fa856b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keypoints(results):\n",
    "\n",
    "    \"\"\"\n",
    "    Extracts and adjusts keypoints for the pose, left hand, and right hand from the results object.\n",
    "    \"\"\"\n",
    "\n",
    "    #ternary operator\n",
    "    #This line creates a flattened array of x, y, z coordinates for 33 pose landmarks if detected, or a zero array of the same shape if no landmarks are found.\n",
    "    # Extract pose landmarks, flattening from 3D (x,y,z) to a 1D array; if not detected, create an array of zeros \"if true the code before it is executed\"\n",
    "    pose = np.array([[res.x, res.y, res.z] for res in results.pose_landmarks.landmark]).flatten() if results.pose_landmarks else np.zeros(33*3) #1D array of 99 zeros (landmarks, coordinate)\n",
    "    \n",
    "    #res is the name given to each item (or landmark)\n",
    "    lh = np.array([[res.x, res.y, res.z] for res in results.left_hand_landmarks.landmark]).flatten() if results.left_hand_landmarks else np.zeros(21*3)\n",
    "    \n",
    "    rh = np.array([[res.x, res.y, res.z] for res in results.right_hand_landmarks.landmark]).flatten() if results.right_hand_landmarks else np.zeros(21*3)\n",
    "\n",
    "    # Set reference points for centering landmarks\n",
    "    nose=pose[:3]   # First three values in pose represent the nose landmark // In MediaPipe’s landmark model, the nose is typically the first landmark in the list of pose landmarks\n",
    "    lh_wrist=lh[:3] #x,y,z\n",
    "    rh_wrist=rh[:3]\n",
    "\n",
    "    # Adjust the landmarks to be centered around the reference points\n",
    "    pose_adjusted = adjust_landmarks(pose,nose)\n",
    "    lh_adjusted = adjust_landmarks(lh,lh_wrist)\n",
    "    rh_adjusted = adjust_landmarks(rh,rh_wrist)\n",
    "    \n",
    "    return pose_adjusted, lh_adjusted, rh_adjusted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40354e16-166a-4211-bd4e-122faaf1be17",
   "metadata": {},
   "source": [
    "## Create List of Selected Words Using Ranges with Zero-Padding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d70edf-a9c9-4263-aeab-12e3cfba94b5",
   "metadata": {},
   "source": [
    "- This cell generates a list of numbers within specified ranges, each formatted as a 4-digit, zero-padded string (e.g., \"0111\", \"0112\"). This could be used to create filenames, labels, or identifiers in a consistent format.\n",
    "\n",
    "**zero padding:**\n",
    "`str(num).zfill(4)`\n",
    "`.zfill(4)` : Fill the string with zeros until it is 4 characters long\n",
    "\n",
    "`.extend()` : Adds all elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06a2c73f-3bcc-476b-ab49-582927178ee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0001', '0002', '0003', '0004', '0005', '0006', '0007', '0008', '0009', '0010', '0011', '0012', '0013', '0014', '0015', '0016', '0017', '0018', '0019', '0020', '0021', '0022', '0023', '0024', '0025', '0026', '0027', '0028', '0029', '0030', '0031', '0032', '0033', '0034', '0035', '0036', '0037', '0038', '0039', '0040', '0041', '0042', '0043', '0044', '0045', '0046', '0047', '0048', '0049', '0050', '0051', '0052', '0053', '0054', '0055', '0056', '0057', '0058', '0059', '0060', '0061', '0062', '0063', '0064', '0065', '0066', '0067', '0068', '0069', '0070', '0071', '0072', '0073', '0074', '0075', '0076', '0077', '0078', '0079', '0080', '0081', '0082', '0083', '0084', '0085', '0086', '0087', '0088', '0089', '0090', '0091', '0092', '0093', '0094', '0095', '0096', '0097', '0098', '0099', '0100', '0101', '0102', '0103', '0104', '0105', '0106', '0107', '0108', '0109', '0110', '0111', '0112', '0113', '0114', '0115', '0116', '0117', '0118', '0119', '0120', '0121', '0122', '0123', '0124', '0125', '0126', '0127', '0128', '0129', '0130', '0131', '0132', '0133', '0134', '0135', '0136', '0137', '0138', '0139', '0140', '0141', '0142', '0143', '0144', '0145', '0146', '0147', '0148', '0149', '0150', '0151', '0152', '0153', '0154', '0155', '0156', '0157', '0158', '0159', '0160', '0161', '0162', '0163', '0164', '0165', '0166', '0167', '0168', '0169', '0170', '0171', '0172', '0173', '0174', '0175', '0176', '0177', '0178', '0179', '0180', '0181', '0182', '0183', '0184', '0185', '0186', '0187', '0188', '0189', '0190', '0191', '0192', '0193', '0194', '0195', '0196', '0197', '0198', '0199', '0200', '0201', '0202', '0203', '0204', '0205', '0206', '0207', '0208', '0209', '0210', '0211', '0212', '0213', '0214', '0215', '0216', '0217', '0218', '0219', '0220', '0221', '0222', '0223', '0224', '0225', '0226', '0227', '0228', '0229', '0230', '0231', '0232', '0233', '0234', '0235', '0236', '0237', '0238', '0239', '0240', '0241', '0242', '0243', '0244', '0245', '0246', '0247', '0248', '0249', '0250', '0251', '0252', '0253', '0254', '0255', '0256', '0257', '0258', '0259', '0260', '0261', '0262', '0263', '0264', '0265', '0266', '0267', '0268', '0269', '0270', '0271', '0272', '0273', '0274', '0275', '0276', '0277', '0278', '0279', '0280', '0281', '0282', '0283', '0284', '0285', '0286', '0287', '0288', '0289', '0290', '0291', '0292', '0293', '0294', '0295', '0296', '0297', '0298', '0299', '0300', '0301', '0302', '0303', '0304', '0305', '0306', '0307', '0308', '0309', '0310', '0311', '0312', '0313', '0314', '0315', '0316', '0317', '0318', '0319', '0320', '0321', '0322', '0323', '0324', '0325', '0326', '0327', '0328', '0329', '0330', '0331', '0332', '0333', '0334', '0335', '0336', '0337', '0338', '0339', '0340', '0341', '0342', '0343', '0344', '0345', '0346', '0347', '0348', '0349', '0350', '0351', '0352', '0353', '0354', '0355', '0356', '0357', '0358', '0359', '0360', '0361', '0362', '0363', '0364', '0365', '0366', '0367', '0368', '0369', '0370', '0371', '0372', '0373', '0374', '0375', '0376', '0377', '0378', '0379', '0380', '0381', '0382', '0383', '0384', '0385', '0386', '0387', '0388', '0389', '0390', '0391', '0392', '0393', '0394', '0395', '0396', '0397', '0398', '0399', '0400', '0401', '0402', '0403', '0404', '0405', '0406', '0407', '0408', '0409', '0410', '0411', '0412', '0413', '0414', '0415', '0416', '0417', '0418', '0419', '0420', '0421', '0422', '0423', '0424', '0425', '0426', '0427', '0428', '0429', '0430', '0431', '0432', '0433', '0434', '0435', '0436', '0437', '0438', '0439', '0440', '0441', '0442', '0443', '0444', '0445', '0446', '0447', '0448', '0449', '0450', '0451', '0452', '0453', '0454', '0455', '0456', '0457', '0458', '0459', '0460', '0461', '0462', '0463', '0464', '0465', '0466', '0467', '0468', '0469', '0470', '0471', '0472', '0473', '0474', '0475', '0476', '0477', '0478', '0479', '0480', '0481', '0482', '0483', '0484', '0485', '0486', '0487', '0488', '0489', '0490', '0491', '0492', '0493', '0494', '0495', '0496', '0497', '0498', '0499', '0500', '0501', '0502']\n"
     ]
    }
   ],
   "source": [
    "# Define the different ranges\n",
    "ranges = [(1, 503)] #single one element\n",
    "\n",
    "# Initialize an empty list to store the results\n",
    "selected_words = []\n",
    "\n",
    "# Iterate over each range\n",
    "for start, end in ranges:\n",
    "    # Extend the list with zero-padded numbers in the current range\n",
    "    selected_words.extend([str(num).zfill(4) for num in range(start, end)]) \n",
    "\n",
    "# Print the result\n",
    "print(selected_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b20748b-17e7-45d1-9bb6-3c812a497be8",
   "metadata": {},
   "source": [
    "## Function to Generate Keypoint Arrays for Videos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f334d3ce-94bf-4d4a-a3bb-1861919570bf",
   "metadata": {},
   "source": [
    "generates arrays of keypoints (important points representing the pose, left hand, and right hand) from video files, storing them as **.npy** files for future use. These keypoints are used in tasks like sign language recognition.\n",
    "`with` statement is used to manage resources (Mediapipe Holistic model) efficiently. It ensures that the resource is properly initialized and closed when its work is done.**memory released, resources freed**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01844f7-1f36-4752-bbb2-7917ade27573",
   "metadata": {},
   "source": [
    "`with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:`\n",
    "`min_detection_confidence=0.5`:\n",
    "If the model’s confidence in detecting a landmark is less than 0.5 (50%), it discards the detection.\n",
    "\n",
    "`min_tracking_confidence=0.5`:\n",
    "Purpose: Sets the confidence threshold for tracking landmarks across frames.\n",
    "Meaning: If the confidence for tracking (linking landmarks across consecutive frames) is below 0.5, the model may stop tracking."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de777f32-e7c9-4608-989d-67bcf21b6dc6",
   "metadata": {},
   "source": [
    "# adjust all paths *******************8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "594c716e-2454-40d6-81df-d494ebb960ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_keypoint_arrays(path,signer,split):\n",
    "    \"\"\"This function generates numpy arrays of keypoints for each video in the specified folder location.\n",
    "    Args:\n",
    "      signer(int): the signer of interest. Could be 01 or 02 or 03\n",
    "      split(str): can be 'train', 'test' or 'val'\n",
    "    \"\"\"\n",
    "    #Create Necessary Directories  \n",
    "    #Creates folders to store the generated keypoints for each signer and dataset split.\n",
    "    os.makedirs('working/npy_arrays',exist_ok = True)\n",
    "    os.makedirs(f'working/npy_arrays/{signer}',exist_ok = True)\n",
    "    os.makedirs(f'working/npy_arrays/{signer}/{split}',exist_ok = True)\n",
    "    \n",
    "    #Specifies where to save the keypoints.\n",
    "    working_path = f'working/npy_arrays/{signer}/{split}'\n",
    "    \n",
    "    #Specifies the path to the folder containing videos.\n",
    "    words_folder = os.path.join(path,str(signer),str(signer), split)\n",
    "\n",
    "\n",
    "    \n",
    "    # Loop through all the subfolders in the Dataset folder\n",
    "    for word in tqdm(selected_words):\n",
    "        #Lists all files within each word subfolder, representing different video files.\n",
    "        video_files = os.listdir(os.path.join(words_folder, word))\n",
    "          # Loop through each video files\n",
    "        for video_file in video_files:\n",
    "                # Open the video file. Retrieves and sorts frames from the video.\n",
    "            video = sorted(os.listdir(os.path.join(words_folder, word, video_file)))\n",
    "\n",
    "            # Initialize the list of keypoints for this video to store extracted keypoints.\n",
    "            pose_keypoints, lh_keypoints, rh_keypoints = [], [], []\n",
    "            with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "              # Loop through the video frames\n",
    "              for frame in video:\n",
    "                  # Perform any necessary preprocessing on the frame (e.g., resizing, normalization)\n",
    "                frame = os.path.join(words_folder, word, video_file,frame)\n",
    "                frame = cv2.imread(frame)\n",
    "#                 frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                \n",
    "                  # Normalize pixel values to the range [0, 1]\n",
    "                # Make detections\n",
    "                image, results = mediapipe_detection(frame, holistic)\n",
    "\n",
    "                # Extract keypoints\n",
    "                pose, lh, rh = extract_keypoints(results)\n",
    "                # Add the keypoints to the list for this video\n",
    "                pose_keypoints.append(pose)\n",
    "                lh_keypoints.append(lh)\n",
    "                rh_keypoints.append(rh)           \n",
    "                \n",
    "                # Save the keypoints for this video to a numpy array (Save Keypoints to Disk)\n",
    "                #Paths to save the keypoints for each part.\n",
    "                pose_directory = os.path.join(working_path, word,'pose_keypoints')\n",
    "                lh_directory = os.path.join(working_path, word,'lh_keypoints')\n",
    "                rh_directory = os.path.join(working_path, word,'rh_keypoints')\n",
    "\n",
    "               # Ensures the directories for storing keypoints exist\n",
    "                if not os.path.exists(pose_directory):\n",
    "                    os.makedirs(pose_directory)\n",
    "\n",
    "                if not os.path.exists(lh_directory):\n",
    "                    os.makedirs(lh_directory)\n",
    "\n",
    "                if not os.path.exists(rh_directory):\n",
    "                    os.makedirs(rh_directory)\n",
    "\n",
    "                #Save Keypoints Arrays as .npy Files\n",
    "                pose_path = os.path.join(pose_directory, video_file)\n",
    "                np.save(pose_path, pose_keypoints)\n",
    "\n",
    "                lh_path = os.path.join(lh_directory, video_file)\n",
    "                np.save(lh_path, lh_keypoints)\n",
    "\n",
    "                rh_path = os.path.join(rh_directory, video_file)\n",
    "                np.save(rh_path, rh_keypoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ad7936-13b3-4396-9af0-492527b33300",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import os\n",
    "#print(os.path.exists('karsl-502'))  # Will print True if the directory exists\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c43781-1f67-48ff-b190-76cde4ec003d",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_keypoint_arrays('working/karsl-502','01','train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7387e8c-293a-4a1f-ac01-0d780d49d368",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_keypoint_arrays('working/karsl-502','01','test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b872eb7b-d1bb-46cb-901e-411d584ef35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_keypoint_arrays('working/karsl-502','02','train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c459b443-2a1e-4078-b310-b355dc9c7ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_keypoint_arrays('working/karsl-502','02','test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0550544-2462-46d7-8f38-23d3f73b939b",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_keypoint_arrays('working/karsl-502','03','train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80fcc98a-1641-45dd-9418-8316b76b034f",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_keypoint_arrays('working/karsl-502','03','test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f877fd4a-e119-4427-ae21-a1941093976c",
   "metadata": {},
   "source": [
    "## Load Data and Filter Sign IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64668341-24ee-487c-a13f-dde9fd410f66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SignID</th>\n",
       "      <th>Sign-Arabic</th>\n",
       "      <th>Sign-English</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>498</td>\n",
       "      <td>ممرضة</td>\n",
       "      <td>nurse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>499</td>\n",
       "      <td>ممرض</td>\n",
       "      <td>orderly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>500</td>\n",
       "      <td>محام</td>\n",
       "      <td>lawyer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>501</td>\n",
       "      <td>انتقال</td>\n",
       "      <td>traveling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>502</td>\n",
       "      <td>تعيين</td>\n",
       "      <td>appointment</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>502 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     SignID Sign-Arabic Sign-English\n",
       "0         1           0            0\n",
       "1         2           1            1\n",
       "2         3           2            2\n",
       "3         4           3            3\n",
       "4         5           4            4\n",
       "..      ...         ...          ...\n",
       "497     498       ممرضة        nurse\n",
       "498     499        ممرض      orderly\n",
       "499     500        محام       lawyer\n",
       "500     501      انتقال    traveling\n",
       "501     502       تعيين  appointment\n",
       "\n",
       "[502 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load an Excel file into a pandas DataFrame (Dataset)\n",
    "karsl_df = pd.read_excel('KARSL-502_Labels.xlsx')\n",
    "\n",
    "# Initialize an empty list to store filtering conditions\n",
    "mask = [] #store boolean values indicating whether each row's SignID is in the selected_words\n",
    "\n",
    "for i in karsl_df['SignID'].values: # Loop over each 'SignID' value in the DataFrame // SignID column values\n",
    "    if str(i).zfill(4) in selected_words : # Check if the zero-padded ID is in selected_words\n",
    "        mask.append(True) # Keep this row\n",
    "    else :\n",
    "        mask.append(False) # Exclude this row\n",
    "\n",
    "# Filter the DataFrame rows where mask is True  \n",
    "karsl_6 = karsl_df[mask].reset_index(drop=True) #Resets the index of the filtered DataFrame and drops the old index.\n",
    "\n",
    "karsl_6 #contains only rows with SignID values in selected_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f40b86c1-e6b9-4862-ab46-9cd092ccfc49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968edaf4-7830-4c25-8362-00c6e1c9dcf8",
   "metadata": {},
   "source": [
    "## Create a Dictionary Mapping Arabic Signs to Their IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bb7317f1-62ef-474e-9fe8-f2004641a3d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 1,\n",
       " 1: 2,\n",
       " 2: 3,\n",
       " 3: 4,\n",
       " 4: 5,\n",
       " 5: 6,\n",
       " 6: 7,\n",
       " 7: 8,\n",
       " 8: 9,\n",
       " 9: 10,\n",
       " 10: 11,\n",
       " 20: 12,\n",
       " 30: 13,\n",
       " 40: 14,\n",
       " 50: 15,\n",
       " 60: 16,\n",
       " 70: 17,\n",
       " 80: 18,\n",
       " 90: 19,\n",
       " 100: 20,\n",
       " 200: 21,\n",
       " 300: 22,\n",
       " 400: 23,\n",
       " 500: 24,\n",
       " 600: 25,\n",
       " 700: 26,\n",
       " 800: 27,\n",
       " 900: 28,\n",
       " 1000: 29,\n",
       " 1000000: 30,\n",
       " 10000000: 31,\n",
       " 'ا': 32,\n",
       " 'ب': 33,\n",
       " 'ت': 34,\n",
       " 'ث': 35,\n",
       " 'ج': 36,\n",
       " 'ح': 37,\n",
       " 'خ': 38,\n",
       " 'د': 39,\n",
       " 'ذ': 40,\n",
       " 'ر': 41,\n",
       " 'ز': 42,\n",
       " 'س': 43,\n",
       " 'ش': 44,\n",
       " 'ص': 45,\n",
       " 'ض': 46,\n",
       " 'ط': 47,\n",
       " 'ظ': 48,\n",
       " 'ع': 49,\n",
       " 'غ': 50,\n",
       " 'ف': 51,\n",
       " 'ق': 52,\n",
       " 'ك': 53,\n",
       " 'ل': 54,\n",
       " 'م': 55,\n",
       " 'ن': 56,\n",
       " 'ه': 57,\n",
       " 'و': 58,\n",
       " 'ي': 59,\n",
       " 'ة': 60,\n",
       " 'أ': 61,\n",
       " 'ؤ': 62,\n",
       " 'ئ': 63,\n",
       " 'ئـ': 64,\n",
       " 'ء': 65,\n",
       " 'إ': 66,\n",
       " 'آ': 67,\n",
       " 'ى': 68,\n",
       " 'لا': 69,\n",
       " 'ال': 70,\n",
       " 'هيكل عظمي': 71,\n",
       " 'جمجة': 72,\n",
       " 'عمود فقري': 73,\n",
       " 'قفص صدري': 74,\n",
       " 'جهاز تنفسي': 75,\n",
       " 'قصبة هوائية': 76,\n",
       " 'رئتان': 77,\n",
       " 'شهيق - زفير': 78,\n",
       " 'جهاز هضمي': 79,\n",
       " 'وجه': 80,\n",
       " 'بلعوم': 81,\n",
       " 'كبد': 82,\n",
       " 'البنكرياس': 83,\n",
       " 'الأمعاء الدقيقة': 84,\n",
       " 'الأمعاء الغليظة': 85,\n",
       " 'الزائدة الدودية': 86,\n",
       " 'جهاز عصبي': 87,\n",
       " 'قلب': 88,\n",
       " 'حواس خمس': 89,\n",
       " 'عضلة': 90,\n",
       " 'أنسجة': 91,\n",
       " 'مستشفى': 92,\n",
       " 'إسعافات أولية': 93,\n",
       " 'جرح نازف': 94,\n",
       " 'حروق': 95,\n",
       " 'مخدر/ بنج': 96,\n",
       " 'عملية جراحية': 97,\n",
       " 'شاش / ضمادة': 98,\n",
       " 'شريط لاصق / بلاستر': 99,\n",
       " 'صيدلية': 100,\n",
       " 'تحليل دم': 101,\n",
       " 'فحص سريري': 102,\n",
       " 'فحص النظر': 103,\n",
       " 'ميزان حرارة': 104,\n",
       " 'سماعة أذن': 105,\n",
       " 'جهاز قياس الضغط': 106,\n",
       " 'نبض القلب': 107,\n",
       " 'تحليل طبي': 108,\n",
       " 'معمل التحاليل / مختبر': 109,\n",
       " 'صورة اشعة': 110,\n",
       " 'التهاب': 111,\n",
       " 'تورم': 112,\n",
       " 'زكام': 113,\n",
       " 'عدوى': 114,\n",
       " 'صداع': 115,\n",
       " 'ألم': 116,\n",
       " 'حمى': 117,\n",
       " 'إسهال': 118,\n",
       " 'إمساك': 119,\n",
       " 'مغص': 120,\n",
       " 'مرض السكر / سكري': 121,\n",
       " 'أزمة قلبية': 122,\n",
       " 'سرطان': 123,\n",
       " 'مرض فقدان المناعة / الإيدز': 124,\n",
       " 'تساقط الشعر': 125,\n",
       " 'سكتة قلبية': 126,\n",
       " 'شلل نصفي': 127,\n",
       " 'شلل دماغي': 128,\n",
       " 'ضغط الدم': 129,\n",
       " 'حساسية': 130,\n",
       " 'حكة / هرش': 131,\n",
       " 'دواء': 132,\n",
       " 'دورة شهرية': 133,\n",
       " 'مريض / مرض': 134,\n",
       " 'كبسولة': 135,\n",
       " 'دواء شراب': 136,\n",
       " 'مرهم': 137,\n",
       " 'قطارة': 138,\n",
       " 'أخذ إبرة': 139,\n",
       " 'تلقيح': 140,\n",
       " 'تطعيم': 141,\n",
       " 'أشعة ليزر': 142,\n",
       " 'مخدرات': 143,\n",
       " 'إدمان': 144,\n",
       " 'توحد / أوتيزم': 145,\n",
       " 'منغولي': 146,\n",
       " 'بكتريا': 147,\n",
       " 'جرثومة': 148,\n",
       " 'فيروس': 149,\n",
       " 'إنتشار': 150,\n",
       " 'إعاقة': 151,\n",
       " 'إعاقة ذهنية': 152,\n",
       " 'اعاقة جسدية': 153,\n",
       " 'اعاقة بصرية': 154,\n",
       " 'إعاقة سمعية': 155,\n",
       " 'وباء': 156,\n",
       " 'مناعة': 157,\n",
       " 'عصب': 158,\n",
       " 'معافى': 159,\n",
       " 'يأكل': 160,\n",
       " 'يشرب': 161,\n",
       " 'ينام': 162,\n",
       " 'يستيقظ': 163,\n",
       " 'يسمع': 164,\n",
       " 'يسكت': 165,\n",
       " 'يشم': 166,\n",
       " 'يصعد': 167,\n",
       " 'ينزل': 168,\n",
       " 'يفتح': 169,\n",
       " 'يقفل ( يغلق )': 170,\n",
       " 'يبني': 171,\n",
       " 'يكسر': 172,\n",
       " 'يمشي': 173,\n",
       " 'يحب': 174,\n",
       " 'يكره': 175,\n",
       " 'يشوي': 176,\n",
       " 'يحرث': 177,\n",
       " 'يزرع': 178,\n",
       " 'يسقي': 179,\n",
       " 'يحصد': 180,\n",
       " 'يفكر': 181,\n",
       " 'يساعد': 182,\n",
       " 'يدخن': 183,\n",
       " 'يدعم': 184,\n",
       " 'يختار': 185,\n",
       " 'ينادي': 186,\n",
       " 'يتنامى': 187,\n",
       " 'يصبغ': 188,\n",
       " 'يقف': 189,\n",
       " 'يستحم': 190,\n",
       " 'يدخل': 191,\n",
       " 'أسرة': 192,\n",
       " 'جدة': 193,\n",
       " 'جد': 194,\n",
       " 'أب': 195,\n",
       " 'أم': 196,\n",
       " 'أخت': 197,\n",
       " 'أخ': 198,\n",
       " 'بنت': 199,\n",
       " 'رضيع': 200,\n",
       " 'توأم': 201,\n",
       " 'رجل': 202,\n",
       " 'شاب': 203,\n",
       " 'شابة': 204,\n",
       " 'حفيد': 205,\n",
       " 'زواج': 206,\n",
       " 'حمل': 207,\n",
       " 'ولادة': 208,\n",
       " 'عم': 209,\n",
       " 'عمة': 210,\n",
       " 'خال': 211,\n",
       " 'خالة': 212,\n",
       " 'ابن الأخ': 213,\n",
       " 'ابن الأخت': 214,\n",
       " 'ابن العم': 215,\n",
       " 'ابن': 216,\n",
       " 'ابنة': 217,\n",
       " 'ناس': 218,\n",
       " 'طلاق': 219,\n",
       " 'خطوبة': 220,\n",
       " 'حفلة': 221,\n",
       " 'وفاة': 222,\n",
       " 'طفل': 223,\n",
       " 'جميل': 224,\n",
       " 'قبيح': 225,\n",
       " 'طويل': 226,\n",
       " 'قصير': 227,\n",
       " 'نحيف': 228,\n",
       " 'سمين': 229,\n",
       " 'غني': 230,\n",
       " 'فقير': 231,\n",
       " 'محبط': 232,\n",
       " 'مشمئز': 233,\n",
       " 'مرتبك': 234,\n",
       " 'قلق': 235,\n",
       " 'مشوش': 236,\n",
       " 'خائف': 237,\n",
       " 'سعيد (مسرور)': 238,\n",
       " 'حزين': 239,\n",
       " 'شجاع': 240,\n",
       " 'جبان': 241,\n",
       " 'طموح': 242,\n",
       " 'معجب': 243,\n",
       " 'غائر من': 244,\n",
       " 'غائر على': 245,\n",
       " 'ودود': 246,\n",
       " 'كريم': 247,\n",
       " 'بخيل': 248,\n",
       " 'طماع': 249,\n",
       " 'كذاب': 250,\n",
       " 'أناني': 251,\n",
       " 'متكبر': 252,\n",
       " 'متواضع': 253,\n",
       " 'شعور': 254,\n",
       " 'تعب': 255,\n",
       " 'بكاء': 256,\n",
       " 'احتقار': 257,\n",
       " 'اعتماد على الذات': 258,\n",
       " 'خفيف': 259,\n",
       " 'ثقيل': 260,\n",
       " 'قديم': 261,\n",
       " 'حسد': 262,\n",
       " 'صدق': 263,\n",
       " 'غدر': 264,\n",
       " 'صبر': 265,\n",
       " 'لوم': 266,\n",
       " 'الحق': 267,\n",
       " 'خيانة': 268,\n",
       " 'إيثار': 269,\n",
       " 'تضحية': 270,\n",
       " 'شفقة': 271,\n",
       " 'ذكي': 272,\n",
       " 'أمام': 273,\n",
       " 'بجانب': 274,\n",
       " 'بعيد': 275,\n",
       " 'بين': 276,\n",
       " 'تحت': 277,\n",
       " 'حول': 278,\n",
       " 'خارج': 279,\n",
       " 'خلف': 280,\n",
       " 'داخل': 281,\n",
       " 'فوق': 282,\n",
       " 'قريب': 283,\n",
       " 'من خلال': 284,\n",
       " 'هنا': 285,\n",
       " 'هناك': 286,\n",
       " 'يسار': 287,\n",
       " 'يمين': 288,\n",
       " 'أهلا وسهلاً': 289,\n",
       " 'السلام عليكم': 290,\n",
       " 'تفضل': 291,\n",
       " 'جار': 292,\n",
       " 'شكراً': 293,\n",
       " 'صديق': 294,\n",
       " 'ضيف': 295,\n",
       " 'عدو': 296,\n",
       " 'عيب': 297,\n",
       " 'هدية': 298,\n",
       " 'بيت': 299,\n",
       " 'جدار': 300,\n",
       " 'سقف': 301,\n",
       " 'باب': 302,\n",
       " 'شباك': 303,\n",
       " 'غرفة': 304,\n",
       " 'غرفة نوم': 305,\n",
       " 'سرير': 306,\n",
       " 'مرتبة سرير ( حشية)': 307,\n",
       " 'شرشف ( غطاء سرير)': 308,\n",
       " 'وسادة ( مخدة)': 309,\n",
       " 'شماعة ( مشجب)': 310,\n",
       " 'خزانة ملابس': 311,\n",
       " 'مطبخ': 312,\n",
       " 'فرن غازي': 313,\n",
       " 'بوتاغاز (طابخ)': 314,\n",
       " 'طبق ( صحن)': 315,\n",
       " 'سكين': 316,\n",
       " 'شوكة': 317,\n",
       " 'ملعقة': 318,\n",
       " 'فنجان': 319,\n",
       " 'مجمد (فريزر)': 320,\n",
       " 'كأس ( كوب)': 321,\n",
       " 'حافظ حرارة ( ترمس)': 322,\n",
       " 'غرفة طعام': 323,\n",
       " 'إبريق': 324,\n",
       " 'طاولة': 325,\n",
       " 'كنكة ( دلة)': 326,\n",
       " 'دورة مياه (حمام)': 327,\n",
       " 'كرسي': 328,\n",
       " 'غسالة': 329,\n",
       " 'منشفة': 330,\n",
       " 'سجادة (زربية)': 331,\n",
       " 'موكيت ( فرش أرضي) moquette': 332,\n",
       " 'ثريا (نجفة)': 333,\n",
       " 'مسجل': 334,\n",
       " 'شريط كاست': 335,\n",
       " 'تلفزيون (تلفاز)': 336,\n",
       " 'طبق هوائي (دش)': 337,\n",
       " 'شريط فيديو': 338,\n",
       " 'كاميرا فيديو': 339,\n",
       " 'كاميرا فوتوغرافية': 340,\n",
       " 'هاتف ( تلفون)': 341,\n",
       " 'غرفة ضيوف': 342,\n",
       " 'فيديو': 343,\n",
       " 'مبخرة': 344,\n",
       " 'مدفأة': 345,\n",
       " 'مفتاح': 346,\n",
       " 'مروحة': 347,\n",
       " 'تدفئة مركزية': 348,\n",
       " 'كهرباء': 349,\n",
       " 'مكيف': 350,\n",
       " 'سلك كهربائي': 351,\n",
       " 'قابس كهربائي ( فيش)': 352,\n",
       " 'حقيبة سفر': 353,\n",
       " 'مكواة': 354,\n",
       " 'ميزان حرارة جوي': 355,\n",
       " 'الله تعالى': 356,\n",
       " 'محمد رسول الله': 357,\n",
       " 'عيسى المسيح': 358,\n",
       " 'القرآن الكريم': 359,\n",
       " 'الخلفاء الراشدون': 360,\n",
       " 'السنة النبوية': 361,\n",
       " 'أركان الإسلام': 362,\n",
       " 'أركان الإيمان': 363,\n",
       " 'الشهادتين': 364,\n",
       " 'يصلي / الصلاة': 365,\n",
       " 'الزكاة': 366,\n",
       " 'الصوم': 367,\n",
       " 'العمرة': 368,\n",
       " 'الحج': 369,\n",
       " 'ملائكة': 370,\n",
       " 'رسول': 371,\n",
       " 'يوم القيامة': 372,\n",
       " 'القضاء والقدر': 373,\n",
       " 'أركان الصلاة': 374,\n",
       " 'خير': 375,\n",
       " 'النية': 376,\n",
       " 'شر': 377,\n",
       " 'طهارة': 378,\n",
       " 'مبطلات الصلاة': 379,\n",
       " 'تيمم': 380,\n",
       " 'يتوضأ / وضوء': 381,\n",
       " 'يؤذن': 382,\n",
       " 'مسح على الخفين': 383,\n",
       " 'صلاة الفجر': 384,\n",
       " 'صلاة الظهر': 385,\n",
       " 'صلاة العصر': 386,\n",
       " 'صلاة المغرب': 387,\n",
       " 'صلاة العشاء': 388,\n",
       " 'خطبة': 389,\n",
       " 'خطبة الجمعة': 390,\n",
       " 'خطيب': 391,\n",
       " 'خطبة العيد': 392,\n",
       " 'مسجد': 393,\n",
       " 'سورة': 394,\n",
       " 'إمام': 395,\n",
       " 'سورة الفاتحة': 396,\n",
       " 'آية': 397,\n",
       " 'ليلة القدر': 398,\n",
       " 'عيد': 399,\n",
       " 'عيد الفطر': 400,\n",
       " 'عيد الأضحى': 401,\n",
       " 'إحرام': 402,\n",
       " 'مكة': 403,\n",
       " 'الكعبة': 404,\n",
       " 'المدينة المنورة': 405,\n",
       " 'منى': 406,\n",
       " 'جبل عرفات': 407,\n",
       " 'الصفا والمروة': 408,\n",
       " 'مزدلفة': 409,\n",
       " 'رمي الجمرات': 410,\n",
       " 'طواف': 411,\n",
       " 'ماء زمزم': 412,\n",
       " 'الأضحية': 413,\n",
       " 'فك الإحرام': 414,\n",
       " 'طواف الوداع': 415,\n",
       " 'المسجد الأقصى': 416,\n",
       " 'يسبح': 417,\n",
       " 'الحمد لله': 418,\n",
       " 'سبحان الله': 419,\n",
       " 'إيمان': 420,\n",
       " 'الشرك بالله': 421,\n",
       " 'أعوذ بالله': 422,\n",
       " 'شيطان': 423,\n",
       " 'جن': 424,\n",
       " 'الضالون': 425,\n",
       " 'المغضوب عليهم': 426,\n",
       " 'صنم': 427,\n",
       " 'زنى': 428,\n",
       " 'الجنة': 429,\n",
       " 'النار': 430,\n",
       " 'روح': 431,\n",
       " 'حقوق': 432,\n",
       " 'واجبات': 433,\n",
       " 'حسنات': 434,\n",
       " 'سيئات': 435,\n",
       " 'حلال': 436,\n",
       " 'حرام': 437,\n",
       " 'مغفرة': 438,\n",
       " 'دين': 439,\n",
       " 'مسيحي': 440,\n",
       " 'يهودي': 441,\n",
       " 'كنيسة': 442,\n",
       " 'إسراء ومعراج': 443,\n",
       " 'حواء': 444,\n",
       " 'آدم': 445,\n",
       " 'صدقة': 446,\n",
       " 'نبي': 447,\n",
       " 'هداية': 448,\n",
       " 'أمانة': 449,\n",
       " 'شهيد': 450,\n",
       " 'حقوق الوالدين': 451,\n",
       " 'عقوق الوالدين': 452,\n",
       " 'مسلم': 453,\n",
       " 'رحمة': 454,\n",
       " 'عيد رأس السنة': 455,\n",
       " 'فروض': 456,\n",
       " 'قبة الصخرة': 457,\n",
       " 'خلق': 458,\n",
       " 'مهندس': 459,\n",
       " 'مصور فوتوغرافي': 460,\n",
       " 'جزار / قصاب': 461,\n",
       " 'سائق': 462,\n",
       " 'صائغ': 463,\n",
       " 'خادم': 464,\n",
       " 'رئيس قسم': 465,\n",
       " 'حداد': 466,\n",
       " 'لحام كهربائي': 467,\n",
       " 'مترجم لغة الإشارة': 468,\n",
       " 'مذيع': 469,\n",
       " 'مترجم لغات': 470,\n",
       " 'مدير': 471,\n",
       " 'سفير': 472,\n",
       " 'وزير': 473,\n",
       " 'ملك / سلطان': 474,\n",
       " 'أمير البلاد / رئيس الجمهورية': 475,\n",
       " 'شيخ': 476,\n",
       " 'محافظ / وال': 477,\n",
       " 'ولي عهد / وكيل وزارة': 478,\n",
       " 'رئيس مجلس الشعب (النواب)': 479,\n",
       " 'أمين عام': 480,\n",
       " 'صحفي': 481,\n",
       " 'رسام': 482,\n",
       " 'خياط / تارزي': 483,\n",
       " 'ضابط': 484,\n",
       " 'طيار': 485,\n",
       " 'جندي': 486,\n",
       " 'حلاق': 487,\n",
       " 'صباغ': 488,\n",
       " 'رجل إطفاء / دفاع مدني': 489,\n",
       " 'نجار': 490,\n",
       " 'معلم / مدرس': 491,\n",
       " 'طباخ': 492,\n",
       " 'فلاح': 493,\n",
       " 'موظف': 494,\n",
       " 'أمين صندوق': 495,\n",
       " 'صيدلي': 496,\n",
       " 'طبيب': 497,\n",
       " 'ممرضة': 498,\n",
       " 'ممرض': 499,\n",
       " 'محام': 500,\n",
       " 'انتقال': 501,\n",
       " 'تعيين': 502}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Key (w): The Arabic name of a sign. Value (i): Its corresponding ID\n",
    "w2id = {w:i for w,i in zip(karsl_6['Sign-Arabic'].values,karsl_6['SignID'].values  )}\n",
    "w2id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd20501d-a59c-4df7-9769-f4398fe8bbe3",
   "metadata": {},
   "source": [
    "## Extract and Print Arabic Sign Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "242379e8-11b5-47fc-b7f9-7d2f21413c50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0' '1' '2' '3' '4' '5' '6' '7' '8' '9' '10' '20' '30' '40' '50' '60'\n",
      " '70' '80' '90' '100' '200' '300' '400' '500' '600' '700' '800' '900'\n",
      " '1000' '1000000' '10000000' 'ا' 'ب' 'ت' 'ث' 'ج' 'ح' 'خ' 'د' 'ذ' 'ر' 'ز'\n",
      " 'س' 'ش' 'ص' 'ض' 'ط' 'ظ' 'ع' 'غ' 'ف' 'ق' 'ك' 'ل' 'م' 'ن' 'ه' 'و' 'ي' 'ة'\n",
      " 'أ' 'ؤ' 'ئ' 'ئـ' 'ء' 'إ' 'آ' 'ى' 'لا' 'ال' 'هيكل عظمي' 'جمجة' 'عمود فقري'\n",
      " 'قفص صدري' 'جهاز تنفسي' 'قصبة هوائية' 'رئتان' 'شهيق - زفير' 'جهاز هضمي'\n",
      " 'وجه' 'بلعوم' 'كبد' 'البنكرياس' 'الأمعاء الدقيقة' 'الأمعاء الغليظة'\n",
      " 'الزائدة الدودية' 'جهاز عصبي' 'قلب' 'حواس خمس' 'عضلة' 'أنسجة' 'مستشفى'\n",
      " 'إسعافات أولية' 'جرح نازف' 'حروق' 'مخدر/ بنج' 'عملية جراحية'\n",
      " 'شاش / ضمادة' 'شريط لاصق / بلاستر' 'صيدلية' 'تحليل دم' 'فحص سريري'\n",
      " 'فحص النظر' 'ميزان حرارة' 'سماعة أذن' 'جهاز قياس الضغط' 'نبض القلب'\n",
      " 'تحليل طبي' 'معمل التحاليل / مختبر' 'صورة اشعة' 'التهاب' 'تورم' 'زكام'\n",
      " 'عدوى' 'صداع' 'ألم' 'حمى' 'إسهال' 'إمساك' 'مغص' 'مرض السكر / سكري'\n",
      " 'أزمة قلبية' 'سرطان' 'مرض فقدان المناعة / الإيدز' 'تساقط الشعر'\n",
      " 'سكتة قلبية' 'شلل نصفي' 'شلل دماغي' 'ضغط الدم' 'حساسية' 'حكة / هرش'\n",
      " 'دواء' 'دورة شهرية' 'مريض / مرض' 'كبسولة' 'دواء شراب' 'مرهم' 'قطارة'\n",
      " 'أخذ إبرة' 'تلقيح' 'تطعيم' 'أشعة ليزر' 'مخدرات' 'إدمان' 'توحد / أوتيزم'\n",
      " 'منغولي' 'بكتريا' 'جرثومة' 'فيروس' 'إنتشار' 'إعاقة' 'إعاقة ذهنية'\n",
      " 'اعاقة جسدية' 'اعاقة بصرية' 'إعاقة سمعية' 'وباء' 'مناعة' 'عصب' 'معافى'\n",
      " 'يأكل' 'يشرب' 'ينام' 'يستيقظ' 'يسمع' 'يسكت' 'يشم' 'يصعد' 'ينزل' 'يفتح'\n",
      " 'يقفل ( يغلق )' 'يبني' 'يكسر' 'يمشي' 'يحب' 'يكره' 'يشوي' 'يحرث' 'يزرع'\n",
      " 'يسقي' 'يحصد' 'يفكر' 'يساعد' 'يدخن' 'يدعم' 'يختار' 'ينادي' 'يتنامى'\n",
      " 'يصبغ' 'يقف' 'يستحم' 'يدخل' 'أسرة' 'جدة' 'جد' 'أب' 'أم' 'أخت' 'أخ' 'بنت'\n",
      " 'رضيع' 'توأم' 'رجل' 'شاب' 'شابة' 'حفيد' 'زواج' 'حمل' 'ولادة' 'عم' 'عمة'\n",
      " 'خال' 'خالة' 'ابن الأخ' 'ابن الأخت' 'ابن العم' 'ابن' 'ابنة' 'ناس' 'طلاق'\n",
      " 'خطوبة' 'حفلة' 'وفاة' 'طفل' 'جميل' 'قبيح' 'طويل' 'قصير' 'نحيف' 'سمين'\n",
      " 'غني' 'فقير' 'محبط' 'مشمئز' 'مرتبك' 'قلق' 'مشوش' 'خائف' 'سعيد (مسرور)'\n",
      " 'حزين' 'شجاع' 'جبان' 'طموح' 'معجب' 'غائر من' 'غائر على' 'ودود' 'كريم'\n",
      " 'بخيل' 'طماع' 'كذاب' 'أناني' 'متكبر' 'متواضع' 'شعور' 'تعب' 'بكاء'\n",
      " 'احتقار' 'اعتماد على الذات' 'خفيف' 'ثقيل' 'قديم' 'حسد' 'صدق' 'غدر' 'صبر'\n",
      " 'لوم' 'الحق' 'خيانة' 'إيثار' 'تضحية' 'شفقة' 'ذكي' 'أمام' 'بجانب' 'بعيد'\n",
      " 'بين' 'تحت' 'حول' 'خارج' 'خلف' 'داخل' 'فوق' 'قريب' 'من خلال' 'هنا' 'هناك'\n",
      " 'يسار' 'يمين' 'أهلا وسهلاً' 'السلام عليكم' 'تفضل' 'جار' 'شكراً' 'صديق'\n",
      " 'ضيف' 'عدو' 'عيب' 'هدية' 'بيت' 'جدار' 'سقف' 'باب' 'شباك' 'غرفة'\n",
      " 'غرفة نوم' 'سرير' 'مرتبة سرير ( حشية)' 'شرشف ( غطاء سرير)'\n",
      " 'وسادة ( مخدة)' 'شماعة ( مشجب)' 'خزانة ملابس' 'مطبخ' 'فرن غازي'\n",
      " 'بوتاغاز (طابخ)' 'طبق ( صحن)' 'سكين' 'شوكة' 'ملعقة' 'فنجان'\n",
      " 'مجمد (فريزر)' 'كأس ( كوب)' 'حافظ حرارة ( ترمس)' 'غرفة طعام' 'إبريق'\n",
      " 'طاولة' 'كنكة ( دلة)' 'دورة مياه (حمام)' 'كرسي' 'غسالة' 'منشفة'\n",
      " 'سجادة (زربية)' 'موكيت ( فرش أرضي) moquette' 'ثريا (نجفة)' 'مسجل'\n",
      " 'شريط كاست' 'تلفزيون (تلفاز)' 'طبق هوائي (دش)' 'شريط فيديو'\n",
      " 'كاميرا فيديو' 'كاميرا فوتوغرافية' 'هاتف ( تلفون)' 'غرفة ضيوف' 'فيديو'\n",
      " 'مبخرة' 'مدفأة' 'مفتاح' 'مروحة' 'تدفئة مركزية' 'كهرباء' 'مكيف'\n",
      " 'سلك كهربائي' 'قابس كهربائي ( فيش)' 'حقيبة سفر' 'مكواة' 'ميزان حرارة جوي'\n",
      " 'الله تعالى' 'محمد رسول الله' 'عيسى المسيح' 'القرآن الكريم'\n",
      " 'الخلفاء الراشدون' 'السنة النبوية' 'أركان الإسلام' 'أركان الإيمان'\n",
      " 'الشهادتين' 'يصلي / الصلاة' 'الزكاة' 'الصوم' 'العمرة' 'الحج' 'ملائكة'\n",
      " 'رسول' 'يوم القيامة' 'القضاء والقدر' 'أركان الصلاة' 'خير' 'النية' 'شر'\n",
      " 'طهارة' 'مبطلات الصلاة' 'تيمم' 'يتوضأ / وضوء' 'يؤذن' 'مسح على الخفين'\n",
      " 'صلاة الفجر' 'صلاة الظهر' 'صلاة العصر' 'صلاة المغرب' 'صلاة العشاء' 'خطبة'\n",
      " 'خطبة الجمعة' 'خطيب' 'خطبة العيد' 'مسجد' 'سورة' 'إمام' 'سورة الفاتحة'\n",
      " 'آية' 'ليلة القدر' 'عيد' 'عيد الفطر' 'عيد الأضحى' 'إحرام' 'مكة' 'الكعبة'\n",
      " 'المدينة المنورة' 'منى' 'جبل عرفات' 'الصفا والمروة' 'مزدلفة'\n",
      " 'رمي الجمرات' 'طواف' 'ماء زمزم' 'الأضحية' 'فك الإحرام' 'طواف الوداع'\n",
      " 'المسجد الأقصى' 'يسبح' 'الحمد لله' 'سبحان الله' 'إيمان' 'الشرك بالله'\n",
      " 'أعوذ بالله' 'شيطان' 'جن' 'الضالون' 'المغضوب عليهم' 'صنم' 'زنى' 'الجنة'\n",
      " 'النار' 'روح' 'حقوق' 'واجبات' 'حسنات' 'سيئات' 'حلال' 'حرام' 'مغفرة' 'دين'\n",
      " 'مسيحي' 'يهودي' 'كنيسة' 'إسراء ومعراج' 'حواء' 'آدم' 'صدقة' 'نبي' 'هداية'\n",
      " 'أمانة' 'شهيد' 'حقوق الوالدين' 'عقوق الوالدين' 'مسلم' 'رحمة'\n",
      " 'عيد رأس السنة' 'فروض' 'قبة الصخرة' 'خلق' 'مهندس' 'مصور فوتوغرافي'\n",
      " 'جزار / قصاب' 'سائق' 'صائغ' 'خادم' 'رئيس قسم' 'حداد' 'لحام كهربائي'\n",
      " 'مترجم لغة الإشارة' 'مذيع' 'مترجم لغات' 'مدير' 'سفير' 'وزير'\n",
      " 'ملك / سلطان' 'أمير البلاد / رئيس الجمهورية' 'شيخ' 'محافظ / وال'\n",
      " 'ولي عهد / وكيل وزارة' 'رئيس مجلس الشعب (النواب)' 'أمين عام' 'صحفي'\n",
      " 'رسام' 'خياط / تارزي' 'ضابط' 'طيار' 'جندي' 'حلاق' 'صباغ'\n",
      " 'رجل إطفاء / دفاع مدني' 'نجار' 'معلم / مدرس' 'طباخ' 'فلاح' 'موظف'\n",
      " 'أمين صندوق' 'صيدلي' 'طبيب' 'ممرضة' 'ممرض' 'محام' 'انتقال' 'تعيين']\n"
     ]
    }
   ],
   "source": [
    "words= np.array([v for v in karsl_6['Sign-Arabic']])\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c798f7-2bab-4310-b115-bea253e352b5",
   "metadata": {},
   "source": [
    "## Create a Label Mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810f9780-e3a6-4284-8bfc-141dcd6d9581",
   "metadata": {},
   "source": [
    "This cell assigns a unique numeric label to each Arabic sign word.\n",
    "\n",
    "`enumerate()`: Assigns a unique index (starting from 0) to each item in the words array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "701f90e9-3ec8-457b-9500-264c1ec39db1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0': 0, '1': 1, '2': 2, '3': 3, '4': 4, '5': 5, '6': 6, '7': 7, '8': 8, '9': 9, '10': 10, '20': 11, '30': 12, '40': 13, '50': 14, '60': 15, '70': 16, '80': 17, '90': 18, '100': 19, '200': 20, '300': 21, '400': 22, '500': 23, '600': 24, '700': 25, '800': 26, '900': 27, '1000': 28, '1000000': 29, '10000000': 30, 'ا': 31, 'ب': 32, 'ت': 33, 'ث': 34, 'ج': 35, 'ح': 36, 'خ': 37, 'د': 38, 'ذ': 39, 'ر': 40, 'ز': 41, 'س': 42, 'ش': 43, 'ص': 44, 'ض': 45, 'ط': 46, 'ظ': 47, 'ع': 48, 'غ': 49, 'ف': 50, 'ق': 51, 'ك': 52, 'ل': 53, 'م': 54, 'ن': 55, 'ه': 56, 'و': 57, 'ي': 58, 'ة': 59, 'أ': 60, 'ؤ': 61, 'ئ': 62, 'ئـ': 63, 'ء': 64, 'إ': 65, 'آ': 66, 'ى': 67, 'لا': 68, 'ال': 69, 'هيكل عظمي': 70, 'جمجة': 71, 'عمود فقري': 72, 'قفص صدري': 73, 'جهاز تنفسي': 74, 'قصبة هوائية': 75, 'رئتان': 76, 'شهيق - زفير': 77, 'جهاز هضمي': 78, 'وجه': 79, 'بلعوم': 80, 'كبد': 81, 'البنكرياس': 82, 'الأمعاء الدقيقة': 83, 'الأمعاء الغليظة': 84, 'الزائدة الدودية': 85, 'جهاز عصبي': 86, 'قلب': 87, 'حواس خمس': 88, 'عضلة': 89, 'أنسجة': 90, 'مستشفى': 91, 'إسعافات أولية': 92, 'جرح نازف': 93, 'حروق': 94, 'مخدر/ بنج': 95, 'عملية جراحية': 96, 'شاش / ضمادة': 97, 'شريط لاصق / بلاستر': 98, 'صيدلية': 99, 'تحليل دم': 100, 'فحص سريري': 101, 'فحص النظر': 102, 'ميزان حرارة': 103, 'سماعة أذن': 104, 'جهاز قياس الضغط': 105, 'نبض القلب': 106, 'تحليل طبي': 107, 'معمل التحاليل / مختبر': 108, 'صورة اشعة': 109, 'التهاب': 110, 'تورم': 111, 'زكام': 112, 'عدوى': 113, 'صداع': 114, 'ألم': 115, 'حمى': 116, 'إسهال': 117, 'إمساك': 118, 'مغص': 119, 'مرض السكر / سكري': 120, 'أزمة قلبية': 121, 'سرطان': 122, 'مرض فقدان المناعة / الإيدز': 123, 'تساقط الشعر': 124, 'سكتة قلبية': 125, 'شلل نصفي': 126, 'شلل دماغي': 127, 'ضغط الدم': 128, 'حساسية': 129, 'حكة / هرش': 130, 'دواء': 131, 'دورة شهرية': 132, 'مريض / مرض': 133, 'كبسولة': 134, 'دواء شراب': 135, 'مرهم': 136, 'قطارة': 137, 'أخذ إبرة': 138, 'تلقيح': 139, 'تطعيم': 140, 'أشعة ليزر': 141, 'مخدرات': 142, 'إدمان': 143, 'توحد / أوتيزم': 144, 'منغولي': 145, 'بكتريا': 146, 'جرثومة': 147, 'فيروس': 148, 'إنتشار': 149, 'إعاقة': 150, 'إعاقة ذهنية': 151, 'اعاقة جسدية': 152, 'اعاقة بصرية': 153, 'إعاقة سمعية': 154, 'وباء': 155, 'مناعة': 156, 'عصب': 157, 'معافى': 158, 'يأكل': 159, 'يشرب': 160, 'ينام': 161, 'يستيقظ': 162, 'يسمع': 163, 'يسكت': 164, 'يشم': 165, 'يصعد': 166, 'ينزل': 167, 'يفتح': 168, 'يقفل ( يغلق )': 169, 'يبني': 170, 'يكسر': 171, 'يمشي': 172, 'يحب': 173, 'يكره': 174, 'يشوي': 175, 'يحرث': 176, 'يزرع': 177, 'يسقي': 178, 'يحصد': 179, 'يفكر': 180, 'يساعد': 181, 'يدخن': 182, 'يدعم': 183, 'يختار': 184, 'ينادي': 185, 'يتنامى': 186, 'يصبغ': 187, 'يقف': 188, 'يستحم': 189, 'يدخل': 190, 'أسرة': 191, 'جدة': 192, 'جد': 193, 'أب': 194, 'أم': 195, 'أخت': 196, 'أخ': 197, 'بنت': 198, 'رضيع': 199, 'توأم': 200, 'رجل': 201, 'شاب': 202, 'شابة': 203, 'حفيد': 204, 'زواج': 205, 'حمل': 206, 'ولادة': 207, 'عم': 208, 'عمة': 209, 'خال': 210, 'خالة': 211, 'ابن الأخ': 212, 'ابن الأخت': 213, 'ابن العم': 214, 'ابن': 215, 'ابنة': 216, 'ناس': 217, 'طلاق': 218, 'خطوبة': 219, 'حفلة': 220, 'وفاة': 221, 'طفل': 222, 'جميل': 223, 'قبيح': 224, 'طويل': 225, 'قصير': 226, 'نحيف': 227, 'سمين': 228, 'غني': 229, 'فقير': 230, 'محبط': 231, 'مشمئز': 232, 'مرتبك': 233, 'قلق': 234, 'مشوش': 235, 'خائف': 236, 'سعيد (مسرور)': 237, 'حزين': 238, 'شجاع': 239, 'جبان': 240, 'طموح': 241, 'معجب': 242, 'غائر من': 243, 'غائر على': 244, 'ودود': 245, 'كريم': 246, 'بخيل': 247, 'طماع': 248, 'كذاب': 249, 'أناني': 250, 'متكبر': 251, 'متواضع': 252, 'شعور': 253, 'تعب': 254, 'بكاء': 255, 'احتقار': 256, 'اعتماد على الذات': 257, 'خفيف': 258, 'ثقيل': 259, 'قديم': 260, 'حسد': 261, 'صدق': 262, 'غدر': 263, 'صبر': 264, 'لوم': 265, 'الحق': 266, 'خيانة': 267, 'إيثار': 268, 'تضحية': 269, 'شفقة': 270, 'ذكي': 271, 'أمام': 272, 'بجانب': 273, 'بعيد': 274, 'بين': 275, 'تحت': 276, 'حول': 277, 'خارج': 278, 'خلف': 279, 'داخل': 280, 'فوق': 281, 'قريب': 282, 'من خلال': 283, 'هنا': 284, 'هناك': 285, 'يسار': 286, 'يمين': 287, 'أهلا وسهلاً': 288, 'السلام عليكم': 289, 'تفضل': 290, 'جار': 291, 'شكراً': 292, 'صديق': 293, 'ضيف': 294, 'عدو': 295, 'عيب': 296, 'هدية': 297, 'بيت': 298, 'جدار': 299, 'سقف': 300, 'باب': 301, 'شباك': 302, 'غرفة': 303, 'غرفة نوم': 304, 'سرير': 305, 'مرتبة سرير ( حشية)': 306, 'شرشف ( غطاء سرير)': 307, 'وسادة ( مخدة)': 308, 'شماعة ( مشجب)': 309, 'خزانة ملابس': 310, 'مطبخ': 311, 'فرن غازي': 312, 'بوتاغاز (طابخ)': 313, 'طبق ( صحن)': 314, 'سكين': 315, 'شوكة': 316, 'ملعقة': 317, 'فنجان': 318, 'مجمد (فريزر)': 319, 'كأس ( كوب)': 320, 'حافظ حرارة ( ترمس)': 321, 'غرفة طعام': 322, 'إبريق': 323, 'طاولة': 324, 'كنكة ( دلة)': 325, 'دورة مياه (حمام)': 326, 'كرسي': 327, 'غسالة': 328, 'منشفة': 329, 'سجادة (زربية)': 330, 'موكيت ( فرش أرضي) moquette': 331, 'ثريا (نجفة)': 332, 'مسجل': 333, 'شريط كاست': 334, 'تلفزيون (تلفاز)': 335, 'طبق هوائي (دش)': 336, 'شريط فيديو': 337, 'كاميرا فيديو': 338, 'كاميرا فوتوغرافية': 339, 'هاتف ( تلفون)': 340, 'غرفة ضيوف': 341, 'فيديو': 342, 'مبخرة': 343, 'مدفأة': 344, 'مفتاح': 345, 'مروحة': 346, 'تدفئة مركزية': 347, 'كهرباء': 348, 'مكيف': 349, 'سلك كهربائي': 350, 'قابس كهربائي ( فيش)': 351, 'حقيبة سفر': 352, 'مكواة': 353, 'ميزان حرارة جوي': 354, 'الله تعالى': 355, 'محمد رسول الله': 356, 'عيسى المسيح': 357, 'القرآن الكريم': 358, 'الخلفاء الراشدون': 359, 'السنة النبوية': 360, 'أركان الإسلام': 361, 'أركان الإيمان': 362, 'الشهادتين': 363, 'يصلي / الصلاة': 364, 'الزكاة': 365, 'الصوم': 366, 'العمرة': 367, 'الحج': 368, 'ملائكة': 369, 'رسول': 370, 'يوم القيامة': 371, 'القضاء والقدر': 372, 'أركان الصلاة': 373, 'خير': 374, 'النية': 375, 'شر': 376, 'طهارة': 377, 'مبطلات الصلاة': 378, 'تيمم': 379, 'يتوضأ / وضوء': 380, 'يؤذن': 381, 'مسح على الخفين': 382, 'صلاة الفجر': 383, 'صلاة الظهر': 384, 'صلاة العصر': 385, 'صلاة المغرب': 386, 'صلاة العشاء': 387, 'خطبة': 388, 'خطبة الجمعة': 389, 'خطيب': 390, 'خطبة العيد': 391, 'مسجد': 392, 'سورة': 393, 'إمام': 394, 'سورة الفاتحة': 395, 'آية': 396, 'ليلة القدر': 397, 'عيد': 398, 'عيد الفطر': 399, 'عيد الأضحى': 400, 'إحرام': 401, 'مكة': 402, 'الكعبة': 403, 'المدينة المنورة': 404, 'منى': 405, 'جبل عرفات': 406, 'الصفا والمروة': 407, 'مزدلفة': 408, 'رمي الجمرات': 409, 'طواف': 410, 'ماء زمزم': 411, 'الأضحية': 412, 'فك الإحرام': 413, 'طواف الوداع': 414, 'المسجد الأقصى': 415, 'يسبح': 416, 'الحمد لله': 417, 'سبحان الله': 418, 'إيمان': 419, 'الشرك بالله': 420, 'أعوذ بالله': 421, 'شيطان': 422, 'جن': 423, 'الضالون': 424, 'المغضوب عليهم': 425, 'صنم': 426, 'زنى': 427, 'الجنة': 428, 'النار': 429, 'روح': 430, 'حقوق': 431, 'واجبات': 432, 'حسنات': 433, 'سيئات': 434, 'حلال': 435, 'حرام': 436, 'مغفرة': 437, 'دين': 438, 'مسيحي': 439, 'يهودي': 440, 'كنيسة': 441, 'إسراء ومعراج': 442, 'حواء': 443, 'آدم': 444, 'صدقة': 445, 'نبي': 446, 'هداية': 447, 'أمانة': 448, 'شهيد': 449, 'حقوق الوالدين': 450, 'عقوق الوالدين': 451, 'مسلم': 452, 'رحمة': 453, 'عيد رأس السنة': 454, 'فروض': 455, 'قبة الصخرة': 456, 'خلق': 457, 'مهندس': 458, 'مصور فوتوغرافي': 459, 'جزار / قصاب': 460, 'سائق': 461, 'صائغ': 462, 'خادم': 463, 'رئيس قسم': 464, 'حداد': 465, 'لحام كهربائي': 466, 'مترجم لغة الإشارة': 467, 'مذيع': 468, 'مترجم لغات': 469, 'مدير': 470, 'سفير': 471, 'وزير': 472, 'ملك / سلطان': 473, 'أمير البلاد / رئيس الجمهورية': 474, 'شيخ': 475, 'محافظ / وال': 476, 'ولي عهد / وكيل وزارة': 477, 'رئيس مجلس الشعب (النواب)': 478, 'أمين عام': 479, 'صحفي': 480, 'رسام': 481, 'خياط / تارزي': 482, 'ضابط': 483, 'طيار': 484, 'جندي': 485, 'حلاق': 486, 'صباغ': 487, 'رجل إطفاء / دفاع مدني': 488, 'نجار': 489, 'معلم / مدرس': 490, 'طباخ': 491, 'فلاح': 492, 'موظف': 493, 'أمين صندوق': 494, 'صيدلي': 495, 'طبيب': 496, 'ممرضة': 497, 'ممرض': 498, 'محام': 499, 'انتقال': 500, 'تعيين': 501}\n"
     ]
    }
   ],
   "source": [
    "label_map = {label:num for num, label in enumerate(words)}\n",
    "print(label_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac2da97-e8c8-4438-ad98-799ee44afc90",
   "metadata": {},
   "source": [
    "## Function for Processing Data into Fixed-Length Sequences for Model Training and Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f928331-3d76-459d-877e-27b7b8cd67d6",
   "metadata": {},
   "source": [
    "This function prepares the data by extracting keypoints from multiple videos, ensuring uniform sequence lengths, and converting the data into arrays ready for use in machine learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6a6ed9-25b7-4992-9302-3722b387208d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data_path,signers,split,f_avg):\n",
    "    \"\"\"\"\n",
    "    This function loads the keypoints arrays for each video sequence of each word performed by the given signers, and extracts \n",
    "    a subsequence of length 'f_avg' from each sequence. Then it converts the sequences and labels to numpy arrays and returns \n",
    "    them as X and y.\n",
    "    \n",
    "    Args:\n",
    "        data_path: Path to the directory containing keypoint data.\n",
    "        signers(list): the signers of interest.\n",
    "        split(str): can be 'train' or 'test'.\n",
    "        f_avg(int): threshold for frame sampling(number of frames to sample per sequence).\n",
    "    \n",
    "    Returns:\n",
    "        X(numpy.ndarray): array of sequences\n",
    "        y(numpy.ndarray): array of one-hot encoded sign labels\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize the lists of sequences and labels\n",
    "    sequences, labels = [], [] #labels: A list to store the corresponding labels for the sequences.\n",
    "\n",
    "    # Iterate through the list of words\n",
    "    for word in tqdm(words): #Loops through all words, with a progress bar provided by the tqdm library.\n",
    "        for signer in signers:\n",
    "            # Iterate through the numpy arrays contained in the directory mentioned below\n",
    "            for sequence in os.listdir(os.path.join(data_path,str(signer), split, str(w2id[word] ).zfill(4), 'lh_keypoints')):\n",
    "                 # Load the left hand array .npy\n",
    "                res_lh = np.load(os.path.join(data_path,str(signer), split, str(w2id[word] ).zfill(4), 'lh_keypoints', sequence))\n",
    "\n",
    "                # Determine how many rows to select\n",
    "                num_frames = min(res_lh.shape[0], f_avg) #Ensures the number of frames doesn't exceed f_avg\n",
    "                #res_lh.shape[0]: The number of frames in the keypoint sequence\n",
    "                \n",
    "                res_lh = res_lh[:num_frames,:] #Truncates the sequence to the desired length\n",
    "               \n",
    "                while num_frames < f_avg:\n",
    "                    res_lh = np.concatenate((res_lh, np.expand_dims(res_lh[-1,:], axis=0)), axis=0) #pad by duplicating the last frame until it reaches f_avg\n",
    "                    num_frames += 1\n",
    "\n",
    "                # Load the right hand array\n",
    "                res_rh = np.load(os.path.join(data_path,str(signer), split, str(w2id[word]).zfill(4), 'rh_keypoints', sequence))\n",
    "\n",
    "                # Determine how many rows to select\n",
    "                num_frames = min(res_rh.shape[0], f_avg)\n",
    "                res_rh = res_rh[:num_frames,:]\n",
    "                while num_frames < f_avg:\n",
    "                    res_rh = np.concatenate((res_rh, np.expand_dims(res_rh[-1,:], axis=0)), axis=0)\n",
    "                    num_frames += 1\n",
    "\n",
    "                # Load the pose array\n",
    "                res_pose = np.load(os.path.join(data_path,str(signer), split, str(w2id[word]).zfill(4), 'pose_keypoints', sequence))\n",
    "\n",
    "                # Determine how many rows to select\n",
    "                num_frames = min(res_pose.shape[0], f_avg)\n",
    "                res_pose = res_pose[:num_frames,:]\n",
    "                while num_frames < f_avg:\n",
    "                    res_pose = np.concatenate((res_pose, np.expand_dims(res_pose[-1,:], axis=0)), axis=0)\n",
    "                    num_frames += 1\n",
    "\n",
    "                # Append the subsequence to the list of sequences\n",
    "                sequences.append(np.concatenate((res_pose,res_lh, res_rh), axis=1)) #axis=1 means the arrays will be concatenated horizontally (along columns)\n",
    "                # Append the label to the list of labels\n",
    "                labels.append(label_map[word])\n",
    "    # Convert the lists of sequences and labels to numpy arrays\n",
    "    X = np.array(sequences)\n",
    "    y = to_categorical(labels).astype(int) #Converts labels into one-hot encoded format using a utility function(likely from keras.utils)\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e16a89-689f-40e2-8517-854a8c370bf0",
   "metadata": {},
   "source": [
    "# new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8c48d82a-6d8c-4dc3-bef4-18081ef75c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data_path,signers,split,f_avg):\n",
    "    \"\"\"\"\n",
    "    This function loads the keypoints arrays for each video sequence of each word performed by the given signers, and extracts \n",
    "    a subsequence of length 'f_avg' from each sequence. Then it converts the sequences and labels to numpy arrays and returns \n",
    "    them as X and y.\n",
    "    \n",
    "    Args:\n",
    "        data_path: Path to the directory containing keypoint data.\n",
    "        signers(list): the signers of interest.\n",
    "        split(str): can be 'train' or 'test'.\n",
    "        f_avg(int): threshold for frame sampling(number of frames to sample per sequence).\n",
    "    \n",
    "    Returns:\n",
    "        X(numpy.ndarray): array of sequences\n",
    "        y(numpy.ndarray): array of one-hot encoded sign labels\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize the lists of sequences and labels\n",
    "    sequences, labels = [], [] #labels: A list to store the corresponding labels for the sequences.\n",
    "\n",
    "    # Iterate through the list of words\n",
    "    for word in tqdm(words):\n",
    "        if word not in w2id:\n",
    "            print(f\"Warning: '{word}' not found in w2id\")\n",
    "            continue\n",
    "        for signer in signers:\n",
    "            # Iterate through the numpy arrays contained in the directory mentioned below\n",
    "            for sequence in os.listdir(os.path.join(data_path,str(signer), split, str(w2id[word] ).zfill(4), 'lh_keypoints')):\n",
    "                 # Load the left hand array .npy\n",
    "                res_lh = np.load(os.path.join(data_path,str(signer), split, str(w2id[word] ).zfill(4), 'lh_keypoints', sequence))\n",
    "\n",
    "                # Determine how many rows to select\n",
    "                num_frames = min(res_lh.shape[0], f_avg) #Ensures the number of frames doesn't exceed f_avg\n",
    "                #res_lh.shape[0]: The number of frames in the keypoint sequence\n",
    "                \n",
    "                res_lh = res_lh[:num_frames,:] #Truncates the sequence to the desired length\n",
    "               \n",
    "                while num_frames < f_avg:\n",
    "                    res_lh = np.concatenate((res_lh, np.expand_dims(res_lh[-1,:], axis=0)), axis=0) #pad by duplicating the last frame until it reaches f_avg\n",
    "                    num_frames += 1\n",
    "\n",
    "                # Load the right hand array\n",
    "                res_rh = np.load(os.path.join(data_path,str(signer), split, str(w2id[word]).zfill(4), 'rh_keypoints', sequence))\n",
    "\n",
    "                # Determine how many rows to select\n",
    "                num_frames = min(res_rh.shape[0], f_avg)\n",
    "                res_rh = res_rh[:num_frames,:]\n",
    "                while num_frames < f_avg:\n",
    "                    res_rh = np.concatenate((res_rh, np.expand_dims(res_rh[-1,:], axis=0)), axis=0)\n",
    "                    num_frames += 1\n",
    "\n",
    "                # Load the pose array\n",
    "                res_pose = np.load(os.path.join(data_path,str(signer), split, str(w2id[word]).zfill(4), 'pose_keypoints', sequence))\n",
    "\n",
    "                # Determine how many rows to select\n",
    "                num_frames = min(res_pose.shape[0], f_avg)\n",
    "                res_pose = res_pose[:num_frames,:]\n",
    "                while num_frames < f_avg:\n",
    "                    res_pose = np.concatenate((res_pose, np.expand_dims(res_pose[-1,:], axis=0)), axis=0)\n",
    "                    num_frames += 1\n",
    "\n",
    "                # Append the subsequence to the list of sequences\n",
    "                sequences.append(np.concatenate((res_pose,res_lh, res_rh), axis=1)) #axis=1 means the arrays will be concatenated horizontally (along columns)\n",
    "                # Append the label to the list of labels\n",
    "                labels.append(label_map[word])\n",
    "    # Convert the lists of sequences and labels to numpy arrays\n",
    "    X = np.array(sequences)\n",
    "    y = to_categorical(labels).astype(int) #Converts labels into one-hot encoded format using a utility function(likely from keras.utils)\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3fed07-5251-4d4d-951a-4dddb8ffb003",
   "metadata": {},
   "source": [
    "## Splitting Training and Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8032a030-656f-44b8-b035-10cf2a210eb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                          | 0/502 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: '0' not found in w2id\n",
      "Warning: '1' not found in w2id\n",
      "Warning: '2' not found in w2id\n",
      "Warning: '3' not found in w2id\n",
      "Warning: '4' not found in w2id\n",
      "Warning: '5' not found in w2id\n",
      "Warning: '6' not found in w2id\n",
      "Warning: '7' not found in w2id\n",
      "Warning: '8' not found in w2id\n",
      "Warning: '9' not found in w2id\n",
      "Warning: '10' not found in w2id\n",
      "Warning: '20' not found in w2id\n",
      "Warning: '30' not found in w2id\n",
      "Warning: '40' not found in w2id\n",
      "Warning: '50' not found in w2id\n",
      "Warning: '60' not found in w2id\n",
      "Warning: '70' not found in w2id\n",
      "Warning: '80' not found in w2id\n",
      "Warning: '90' not found in w2id\n",
      "Warning: '100' not found in w2id\n",
      "Warning: '200' not found in w2id\n",
      "Warning: '300' not found in w2id\n",
      "Warning: '400' not found in w2id\n",
      "Warning: '500' not found in w2id\n",
      "Warning: '600' not found in w2id\n",
      "Warning: '700' not found in w2id\n",
      "Warning: '800' not found in w2id\n",
      "Warning: '900' not found in w2id\n",
      "Warning: '1000' not found in w2id\n",
      "Warning: '1000000' not found in w2id\n",
      "Warning: '10000000' not found in w2id\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "00%|████████████████████████████████████████████████████████████████████████████████| 502/502 [38:23<00:00,  4.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31788, 48, 225)\n",
      "(31788, 502)\n",
      "(7948, 48, 225)\n",
      "(7948, 502)\n"
     ]
    }
   ],
   "source": [
    "#train and validation splits\n",
    "data_path = 'working/npy_arrays'\n",
    "X_train,y_train=preprocess_data(data_path,['01','02'],'train',48)\n",
    "# X_train,y_train=preprocess_data(data_path,['01','02'],'train',48)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_val.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "517db3cc-7dd1-48ac-ac70-8d2b7b10b04f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                          | 0/502 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: '0' not found in w2id\n",
      "Warning: '1' not found in w2id\n",
      "Warning: '2' not found in w2id\n",
      "Warning: '3' not found in w2id\n",
      "Warning: '4' not found in w2id\n",
      "Warning: '5' not found in w2id\n",
      "Warning: '6' not found in w2id\n",
      "Warning: '7' not found in w2id\n",
      "Warning: '8' not found in w2id\n",
      "Warning: '9' not found in w2id\n",
      "Warning: '10' not found in w2id\n",
      "Warning: '20' not found in w2id\n",
      "Warning: '30' not found in w2id\n",
      "Warning: '40' not found in w2id\n",
      "Warning: '50' not found in w2id\n",
      "Warning: '60' not found in w2id\n",
      "Warning: '70' not found in w2id\n",
      "Warning: '80' not found in w2id\n",
      "Warning: '90' not found in w2id\n",
      "Warning: '100' not found in w2id\n",
      "Warning: '200' not found in w2id\n",
      "Warning: '300' not found in w2id\n",
      "Warning: '400' not found in w2id\n",
      "Warning: '500' not found in w2id\n",
      "Warning: '600' not found in w2id\n",
      "Warning: '700' not found in w2id\n",
      "Warning: '800' not found in w2id\n",
      "Warning: '900' not found in w2id\n",
      "Warning: '1000' not found in w2id\n",
      "Warning: '1000000' not found in w2id\n",
      "Warning: '10000000' not found in w2id\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "00%|████████████████████████████████████████████████████████████████████████████████| 502/502 [06:54<00:00,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7536, 48, 225)\n",
      "(7536, 502)\n"
     ]
    }
   ],
   "source": [
    "#test split\n",
    "# X_test,y_test=preprocess_data(data_path,['01','02'],'test',48)\n",
    "X_test,y_test=preprocess_data(data_path,['01','02',],'test',48)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "21c85190-cbaf-4d51-b844-691b034a8d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Bidirectional LSTM model with Attention\n",
    "\n",
    "    \n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True)),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(len(words), activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "\n",
    "# Set up early stopping\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',  # Metric to monitor for early stopping\n",
    "    mode='min',  # Set mode to 'min' for minimizing the metric\n",
    "    patience=5,  # Number of epochs with no improvement before stopping\n",
    "    restore_best_weights=True,  # Restore the best model weights\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "28a806f8-c6a1-4186-86c9-018e597d30bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "994/994 [==============================] - 100s 57ms/step - loss: 4.1851 - categorical_accuracy: 0.1291 - val_loss: 2.7088 - val_categorical_accuracy: 0.3037\n",
      "Epoch 2/50\n",
      "994/994 [==============================] - 36s 36ms/step - loss: 1.9554 - categorical_accuracy: 0.4827 - val_loss: 1.4532 - val_categorical_accuracy: 0.6066\n",
      "Epoch 3/50\n",
      "994/994 [==============================] - 38s 39ms/step - loss: 1.1348 - categorical_accuracy: 0.6864 - val_loss: 0.9798 - val_categorical_accuracy: 0.7325\n",
      "Epoch 4/50\n",
      "994/994 [==============================] - 37s 37ms/step - loss: 0.7544 - categorical_accuracy: 0.7904 - val_loss: 0.7297 - val_categorical_accuracy: 0.7992\n",
      "Epoch 5/50\n",
      "994/994 [==============================] - 38s 39ms/step - loss: 0.5619 - categorical_accuracy: 0.8432 - val_loss: 0.5992 - val_categorical_accuracy: 0.8314\n",
      "Epoch 6/50\n",
      "994/994 [==============================] - 46s 46ms/step - loss: 0.4327 - categorical_accuracy: 0.8790 - val_loss: 0.4881 - val_categorical_accuracy: 0.8668\n",
      "Epoch 7/50\n",
      "994/994 [==============================] - 32s 32ms/step - loss: 0.3516 - categorical_accuracy: 0.9000 - val_loss: 0.4499 - val_categorical_accuracy: 0.8771\n",
      "Epoch 8/50\n",
      "994/994 [==============================] - 40s 40ms/step - loss: 0.2981 - categorical_accuracy: 0.9150 - val_loss: 0.4096 - val_categorical_accuracy: 0.8845\n",
      "Epoch 9/50\n",
      "994/994 [==============================] - 41s 41ms/step - loss: 0.2542 - categorical_accuracy: 0.9257 - val_loss: 0.3475 - val_categorical_accuracy: 0.9053\n",
      "Epoch 10/50\n",
      "994/994 [==============================] - 41s 41ms/step - loss: 0.2192 - categorical_accuracy: 0.9347 - val_loss: 0.2805 - val_categorical_accuracy: 0.9243\n",
      "Epoch 11/50\n",
      "994/994 [==============================] - 40s 41ms/step - loss: 0.2038 - categorical_accuracy: 0.9384 - val_loss: 0.2999 - val_categorical_accuracy: 0.9109\n",
      "Epoch 12/50\n",
      "994/994 [==============================] - 41s 41ms/step - loss: 0.1558 - categorical_accuracy: 0.9528 - val_loss: 0.2573 - val_categorical_accuracy: 0.9282\n",
      "Epoch 13/50\n",
      "994/994 [==============================] - 40s 40ms/step - loss: 0.1628 - categorical_accuracy: 0.9505 - val_loss: 0.2460 - val_categorical_accuracy: 0.9289\n",
      "Epoch 14/50\n",
      "994/994 [==============================] - 42s 42ms/step - loss: 0.1354 - categorical_accuracy: 0.9594 - val_loss: 0.2408 - val_categorical_accuracy: 0.9337\n",
      "Epoch 15/50\n",
      "994/994 [==============================] - 41s 42ms/step - loss: 0.1323 - categorical_accuracy: 0.9585 - val_loss: 0.2201 - val_categorical_accuracy: 0.9411\n",
      "Epoch 16/50\n",
      "994/994 [==============================] - 44s 44ms/step - loss: 0.1210 - categorical_accuracy: 0.9624 - val_loss: 0.2008 - val_categorical_accuracy: 0.9487\n",
      "Epoch 17/50\n",
      "994/994 [==============================] - 43s 43ms/step - loss: 0.1052 - categorical_accuracy: 0.9673 - val_loss: 0.2277 - val_categorical_accuracy: 0.9361\n",
      "Epoch 18/50\n",
      "994/994 [==============================] - 48s 48ms/step - loss: 0.0966 - categorical_accuracy: 0.9700 - val_loss: 0.2361 - val_categorical_accuracy: 0.9381\n",
      "Epoch 19/50\n",
      "994/994 [==============================] - 48s 49ms/step - loss: 0.0894 - categorical_accuracy: 0.9723 - val_loss: 0.2045 - val_categorical_accuracy: 0.9468\n",
      "Epoch 20/50\n",
      "994/994 [==============================] - 47s 47ms/step - loss: 0.1002 - categorical_accuracy: 0.9684 - val_loss: 0.1780 - val_categorical_accuracy: 0.9577\n",
      "Epoch 21/50\n",
      "994/994 [==============================] - 47s 47ms/step - loss: 0.0737 - categorical_accuracy: 0.9765 - val_loss: 0.1978 - val_categorical_accuracy: 0.9512\n",
      "Epoch 22/50\n",
      "994/994 [==============================] - 45s 45ms/step - loss: 0.0857 - categorical_accuracy: 0.9738 - val_loss: 0.2133 - val_categorical_accuracy: 0.9433\n",
      "Epoch 23/50\n",
      "994/994 [==============================] - 47s 47ms/step - loss: 0.0736 - categorical_accuracy: 0.9767 - val_loss: 0.1501 - val_categorical_accuracy: 0.9635\n",
      "Epoch 24/50\n",
      "994/994 [==============================] - 47s 47ms/step - loss: 0.0720 - categorical_accuracy: 0.9783 - val_loss: 0.1510 - val_categorical_accuracy: 0.9640\n",
      "Epoch 25/50\n",
      "994/994 [==============================] - 46s 46ms/step - loss: 0.0650 - categorical_accuracy: 0.9793 - val_loss: 0.1477 - val_categorical_accuracy: 0.9626\n",
      "Epoch 26/50\n",
      "994/994 [==============================] - 45s 46ms/step - loss: 0.0625 - categorical_accuracy: 0.9808 - val_loss: 0.2183 - val_categorical_accuracy: 0.9412\n",
      "Epoch 27/50\n",
      "994/994 [==============================] - 47s 47ms/step - loss: 0.0604 - categorical_accuracy: 0.9814 - val_loss: 0.1325 - val_categorical_accuracy: 0.9713\n",
      "Epoch 28/50\n",
      "994/994 [==============================] - 48s 48ms/step - loss: 0.0557 - categorical_accuracy: 0.9825 - val_loss: 0.1429 - val_categorical_accuracy: 0.9697\n",
      "Epoch 29/50\n",
      "994/994 [==============================] - 47s 47ms/step - loss: 0.0623 - categorical_accuracy: 0.9801 - val_loss: 0.1237 - val_categorical_accuracy: 0.9732\n",
      "Epoch 30/50\n",
      "994/994 [==============================] - 47s 47ms/step - loss: 0.0604 - categorical_accuracy: 0.9810 - val_loss: 0.1585 - val_categorical_accuracy: 0.9599\n",
      "Epoch 31/50\n",
      "994/994 [==============================] - 48s 48ms/step - loss: 0.0390 - categorical_accuracy: 0.9884 - val_loss: 0.1751 - val_categorical_accuracy: 0.9612\n",
      "Epoch 32/50\n",
      "994/994 [==============================] - 46s 46ms/step - loss: 0.0534 - categorical_accuracy: 0.9836 - val_loss: 0.1210 - val_categorical_accuracy: 0.9721\n",
      "Epoch 33/50\n",
      "994/994 [==============================] - 45s 45ms/step - loss: 0.0482 - categorical_accuracy: 0.9851 - val_loss: 0.1221 - val_categorical_accuracy: 0.9755\n",
      "Epoch 34/50\n",
      "994/994 [==============================] - 44s 45ms/step - loss: 0.0446 - categorical_accuracy: 0.9861 - val_loss: 0.2039 - val_categorical_accuracy: 0.9548\n",
      "Epoch 35/50\n",
      "994/994 [==============================] - 45s 45ms/step - loss: 0.0492 - categorical_accuracy: 0.9855 - val_loss: 0.2350 - val_categorical_accuracy: 0.9456\n",
      "Epoch 36/50\n",
      "994/994 [==============================] - 46s 46ms/step - loss: 0.0598 - categorical_accuracy: 0.9819 - val_loss: 0.1499 - val_categorical_accuracy: 0.9650\n",
      "Epoch 37/50\n",
      "994/994 [==============================] - 46s 46ms/step - loss: 0.0297 - categorical_accuracy: 0.9908 - val_loss: 0.1176 - val_categorical_accuracy: 0.9772\n",
      "Epoch 38/50\n",
      "994/994 [==============================] - 47s 47ms/step - loss: 0.0530 - categorical_accuracy: 0.9842 - val_loss: 0.1367 - val_categorical_accuracy: 0.9687\n",
      "Epoch 39/50\n",
      "994/994 [==============================] - 47s 47ms/step - loss: 0.0306 - categorical_accuracy: 0.9908 - val_loss: 0.1286 - val_categorical_accuracy: 0.9737\n",
      "Epoch 40/50\n",
      "994/994 [==============================] - 46s 46ms/step - loss: 0.0463 - categorical_accuracy: 0.9857 - val_loss: 0.2563 - val_categorical_accuracy: 0.9371\n",
      "Epoch 41/50\n",
      "994/994 [==============================] - 45s 46ms/step - loss: 0.0401 - categorical_accuracy: 0.9867 - val_loss: 0.1245 - val_categorical_accuracy: 0.9737\n",
      "Epoch 42/50\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "994/994 [==============================] - 45s 46ms/step - loss: 0.0311 - categorical_accuracy: 0.9906 - val_loss: 0.1324 - val_categorical_accuracy: 0.9719\n",
      "Epoch 42: early stopping\n"
     ]
    }
   ],
   "source": [
    "model_training_history = model.fit(X_train, y_train, batch_size=32, validation_data=(X_val,y_val), validation_batch_size=32, epochs=50, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "262d260d-4ea3-46f1-a8f2-a60db70c6bb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "994/994 [==============================] - 19s 18ms/step - loss: 0.0207 - categorical_accuracy: 0.9940\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on train data\n",
    "model_evaluation_history = model.evaluate(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fa9b50a2-f1bc-4b41-807a-043860b20f5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "236/236 [==============================] - 5s 21ms/step - loss: 0.1179 - categorical_accuracy: 0.9770\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on test data\n",
    "model_evaluation_history = model.evaluate(X_test, y_test)\n",
    "#Evaluate signers ****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "36788930-b119-47c5-8616-bf6e7231ad2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_4_layer_call_fn while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: working/LSTM_Model_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: working/LSTM_Model_1\\assets\n"
     ]
    }
   ],
   "source": [
    "# model.save('WLASL (World Level American Sign Language)/Saved Model/LSTM_Model.h5')  # Saves the model in HDF5 format\n",
    "# Or\n",
    "model.save('working/LSTM_Model_1.h5')  # Saves in TensorFlow SavedModel format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c8d65665-e163-4faa-bfc4-0b07d6c0387f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": []
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import FileLinks\n",
    "\n",
    "# Create a download link\n",
    "FileLinks(\"working/label_map.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5feb20ce-5650-449a-b97b-27e991145261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label_map saved to 'label_map.json'\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Your existing label_map\n",
    "label_map = {label: num for num, label in enumerate(words)}\n",
    "\n",
    "# Save to a JSON file\n",
    "with open(\"working/label_map.json\", \"w\") as file:\n",
    "    json.dump(label_map, file, indent=4)\n",
    "\n",
    "print(\"label_map saved to 'label_map.json'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84946d60-2310-444b-8909-1ab170c7c9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metric(model_training_history, metric_name_1, metric_name_2, plot_name):\n",
    "    '''\n",
    "    This function will plot the metrics passed to it in a graph.\n",
    "    Args:\n",
    "        model_training_history: A history object containing a record of training and validation \n",
    "                                loss values and metrics values at successive epochs\n",
    "        metric_name_1:          The name of the first metric that needs to be plotted in the graph.\n",
    "        metric_name_2:          The name of the second metric that needs to be plotted in the graph.\n",
    "        plot_name:              The title of the graph.\n",
    "    '''\n",
    "    \n",
    "    # Get metric values using metric names as identifiers.\n",
    "    metric_value_1 = model_training_history.history[metric_name_1]\n",
    "    metric_value_2 = model_training_history.history[metric_name_2]\n",
    "    \n",
    "    # Construct a range object which will be used as x-axis (horizontal plane) of the graph.\n",
    "    epochs = range(len(metric_value_1))\n",
    "\n",
    "    # Plot the Graph.\n",
    "    plt.plot(epochs, metric_value_1, 'blue', label = metric_name_1)\n",
    "    plt.plot(epochs, metric_value_2, 'red', label = metric_name_2)\n",
    "\n",
    "    # Add title to the plot.\n",
    "    plt.title(str(plot_name))\n",
    "\n",
    "    # Add legend to the plot.\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5153ca51-91aa-403f-bc57-342208d04e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the training and validation loss metrices.\n",
    "plot_metric(model_training_history, 'loss', 'val_loss', 'Total Loss vs Total Validation Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7661eb9-846c-4077-9460-565f4ba26293",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicted sign\n",
    "res = model.predict(X_test)\n",
    "words[np.argmax(res[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5c1799-94fa-4c83-8a3c-850f34b90371",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Real sign\n",
    "words[np.argmax(y_test[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3606d482-477b-4718-ad56-aaba19859739",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the loss and accuracy from model_evaluation_history.\n",
    "model_evaluation_loss, model_evaluation_accuracy = model_evaluation_history\n",
    "\n",
    "# Define the string date format.\n",
    "# Get the current Date and Time in a DateTime Object.\n",
    "# Convert the DateTime object to string according to the style mentioned in date_time_format string.\n",
    "date_time_format = '%Y_%m_%d__%H_%M_%S'\n",
    "current_date_time_dt = dt.datetime.now()\n",
    "current_date_time_string = dt.datetime.strftime(current_date_time_dt, date_time_format)\n",
    "\n",
    "# Define a useful name for our model to make it easy for us while navigating through multiple saved models.\n",
    "model_file_name = f'Kaleem_model_2_signers___Date_Time_{current_date_time_string}___Loss_{model_evaluation_loss}___Accuracy_{model_evaluation_accuracy}.h5'\n",
    "\n",
    "# Save your Model.\n",
    "model.save(model_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880695dc-e678-4c0c-a2c5-8d9deba03321",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be38a9af-be40-486b-b874-877b5a193647",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_key_by_value(dictionary, value):\n",
    "    for key, val in dictionary.items():\n",
    "        if val == value:\n",
    "            return key\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0977b76f-74f7-4ffd-bc49-1788349a1e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrue = np.argmax(y_test, axis=1).tolist()\n",
    "yhat = np.argmax(yhat, axis=1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacdb56e-fd6b-4bbc-ba49-2c90507ed7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = []\n",
    "for v in ytrue:\n",
    "    y.append(get_key_by_value(label_map, v))\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40ee317-f63b-4cff-913f-a6011d514fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [karsl_6[karsl_6['Sign-Arabic'] == v]['Sign-English'].values[0] for v in y]\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3503dd7-576f-41d8-a7fb-006d9049986c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred = []\n",
    "for v in yhat:\n",
    "    ypred.append(get_key_by_value(label_map, v))\n",
    "print(ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a583197-8fbe-40e8-802d-ff229025affc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred = [karsl_6[karsl_6['Sign-Arabic'] == v]['Sign-English'].values[0] for v in ypred]\n",
    "print(ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea319bd8-0a5c-4f30-84d5-57f3e9c0d1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming y and ypred are your target labels and predicted labels, respectively\n",
    "\n",
    "# Select the first 20 classes\n",
    "y_subset = y[:200]\n",
    "ypred_subset = ypred[:200]\n",
    "\n",
    "# Get unique class labels\n",
    "class_labels = np.unique(y_subset)\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(y_subset, ypred_subset, labels=class_labels)\n",
    "\n",
    "# Create a DataFrame from the confusion matrix\n",
    "df_cm = pd.DataFrame(cm, index=class_labels, columns=class_labels)\n",
    "df_cm.index.name = 'Actual'\n",
    "df_cm.columns.name = 'Predicted'\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.set(font_scale=1.3)  # for label size\n",
    "sns.heatmap(df_cm, cmap=\"Blues\", annot=True, fmt=\"d\", annot_kws={\"size\": 12})\n",
    "plt.title(\"Confusion Matrix - First 20 Classes\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
